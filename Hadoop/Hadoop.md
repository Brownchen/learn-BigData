# Hadoop



### 分布式文件存储系统——HDFS
HDFS是Hadoop下的分布式文件系统，具有高容错、高吞吐量等特性，可以部署在低成本的硬件上。

构建于单个磁盘之上的一般文件系统，会将文件划分为文件块，并将这些文件块存储到磁盘块上（文件块大小是磁盘块的整数倍）。

而HDFS中也有这种**[数据块](# HDFS中使用数据块的好处)**（block）的概念。**集群中的所有硬件设备都会被分为block，而文件则会被分为块大小的多个分块(chunk)，这些分块被保存为多个副本存储在集群中的多个节点中**。HDFS的block一般比较大（128M），这是为了**最小化寻址开销**，这样传输一个由多个块组成的大文件的时间主要取决于磁盘的传输速率。

#### 1、HDFS设计原理
##### 1.1 HDFS架构

![image-20200918153654839](D:%5CJob%5Clearn-BigData%5CHadoop%5CHadoop.assets%5Cimage-20200918153654839.png)

HDFS遵循主/从架构，即一个namenode(NN)和多个datanode(DN):

- **namenode**：管理**文件系统的命名空间**，维护着文件系统树以及整棵树内所有文件和目录，例如打开、关闭、重命名文件和目录等操作。这些信息以：**命名空间镜像文件**和**编辑日志文件**的形式永久保存在本地磁盘中。另外，namenode记录着每个文件中各个块所在的数据节点信息。
- **datanode**：是文件系统的工作节点。它们根据需要**存储并检索数据块**（一般是受客户端或namenode的调度），并且定期向namenode发送他们所存储的数据块列表。



##### 1.2 文件系统命名空间

HDFS的文件系统命名空间的层次结构与大多数文件系统类似（如Linux），支持目录和文件的创建、移动、删除和重命名等操作，支持配置用户和访问权限，但**不支持[硬链接和软链接](# Linux的硬链接与软链接)**。



##### 1.3 数据复制

由于Hadoop被设计运行在廉价的机器上，这意味着硬件是不可靠的，因此，为了保证容错性，HDFS提供了数据复制机制。HDFS将每个文件存储为一系列**块**，每个块有多个副本来保证容错，块的大小和复制因子可以自行配置（默认情况下，块大小是128M，复制因子是3）。

![image-20200918153718359](D:%5CJob%5Clearn-BigData%5CHadoop%5CHadoop.assets%5Cimage-20200918153718359.png)



##### 1.4 数据复制的实现原理

大型的HDFS实例常常部署在多个机架上的多台服务器上，不同机架上的两台服务器通过交换机进行通讯。通常情况下，同一机架上的服务器间的网络带宽大于不同机架上服务器之间的的带宽。因此，HDFS采用**机架感知副本放置策略**，常见情况下，复制因子为3时：

写入程序位于datanode上时，优先将写入文件的一个副本放在该datanode上，否则随机放在随机datanode上。之后在另一个远程机架上的任意一个节点上存放另一个副本，并在该机架上的另一个节点上放置最后一个副本。此策略可以减少机架之间的写入流量，从而提高写入性能。
![image-20200918153735051](D:%5CJob%5Clearn-BigData%5CHadoop%5CHadoop.assets%5Cimage-20200918153735051.png)

当复制因子大于3，则随机确定第4个和之后的副本放置位置，不允许同一个datanode上具有同一个块的多个副本。



##### 1.5 副本的选择

为了最大限度地减少带宽消耗和读取延迟，HDFS在执行读取请求时，优先读取距离读取器最近的副本。



##### 1.6 架构的稳定性

- 心跳机制和重新复制

  每个datanode会定期向namenode发送心跳消息，如果超过指定时间没有收到心跳消息，则将datanode标记为死亡。由于数据不再可用，可能会导致某些块的复制因子小于指定值，namenode会在必要的时候重新复制。

- 数据的完整性

  当整个系统需要处理的数据量达到Hadoop的处理极限时，数据被损坏的概率是很大的。因此，HDFS需要提供数据完整性机制来保证数据的完整性，具体来说就是利用CRC（循环冗余校验）。

  当客户端创建HDFS文件时，它会计算文件的**每个数据块的校验和**，并将校验和存储在HDFS的命名空间下的隐藏文件中。当客户端检索文件内容时，它会验证从每个datanode接收的数据是否与存储在HDFS命名空间中的校验和匹配。若匹配失败，则证明数据已经损坏，此时客户端会选择其他datanode上的副本。

- 元数据的磁盘故障
  namenode上包含了元数据（**FsImage**和**EditLog**），因此当那么浓的损坏后，整个文件系统的所有文件都会丢失。因此，namenode的容错性非常重要，为此Hadoop为此提供了两种机制：**备份元数据**和在另一个单独的物理计算机上运行一个**辅助namenode**。

- 支持快照

  快照支持在特定时刻存储数据副本，在数据意外损坏时，可以通过回滚操作恢复到健康的数据状态。
  
  

#### 2、HDFS的特点
##### 2.1 高容错
##### 2.2 高吞吐量
##### 2.3 大文件支持
##### 2.4 简单一致性模型
##### 2.5 跨平台移植性



#### 参考

##### Linux的硬链接与软链接

##### HDFS中使用数据块的好处

对分布式文件系统中的块进行抽象会带来很多好处。

- 一个文件的大小可以大于网络中任意一个磁盘的容量，组成文件的所有数据块可以被分散在集群中的多个磁盘上；
- 使用数据块作为存储单元，大大简化了存储子系统的设计。由于数据块的大小是固定的，可以很容易知道单个磁盘能存储多少个块。且数据块只需要存储大块的数据，而文件的元数据可以单独存储，方便管理；
- 每个块可以备份到多个地方，保证了文件系统的容错性和数据的完整性。



### 分布式计算框架——MapReduce

MapReduce是一种用于数据处理的编程模型，本质上是并行运行的。可以将大规模数据分析任务分发给拥有多机器的数据中心。

MapReduce作业通过将输入的数据集拆分为独立的块，这些块由map以并行的方式处理，框架对map的输出进行排序，然后输入到reduce中。MR框架专门用于<key,value>键值对处理。

![image-20200918172730657](D:%5CJob%5Clearn-BigData%5CHadoop%5CHadoop.assets%5Cimage-20200918172730657.png)

MapReduce作业(job)是客户端需要执行的一个工作单元，包括：输入数据、MapReduce程序和配置信息。

Hadoop将MapReduce的输入数据划分为等长的小数据块，称为输入分片（分片），然后为每个分片构建一个map任务。Hadoop在存储有输入数据（HDFS中的数据）的节点上运行map任务，可以无需使用集群带宽资源，这就是所谓的“数据本地化优化”。然后将排序过的map输出数据发送到运行reduce任务的节点上进行合并，然后执行reduce函数。



### 集群资源管理器——YARN

